# PUFO_Words

Analyse der Podcast-Episoden von "Das Podcast-Ufo" als Text.
Web App die es erlaubt nachzuschauen welche W√∂rter in welchen Podcast Folgen wie h√§ufig gesagt wurden. 
Entwickelt, weil ich eine Folge gesucht hatte aber nur noch grob wusste was gesagt wurde.

üöÄ **[Zur Podcast Folgen Analyse](https://pufo-words.streamlit.app/)** üéß

![App Screenshot](app_example.png "Screenshot")

## Projekt√ºberblick

Dieses Projekt l√§dt alle Episoden aus dem RSS-Feed des Podcasts, transkribiert sie mit Whisper und analysiert die Texte mit spaCy. Die Ergebnisse werden in CSV- und JSON-Dateien gespeichert und k√∂nnen mit einer Streamlit-App interaktiv ausgewertet werden.

- **Transkription:** Whisper wandelt die Audiodateien in Text um.
- **Textanalyse:** spaCy zerlegt die Texte in Lemmata (Wortst√§mme) und z√§hlt deren Vorkommen.
- **Stoppw√∂rter:** H√§ufige W√∂rter wie ‚Äûund‚Äú, ‚Äûoder‚Äú, ‚Äûdas‚Äú werden entfernt.
- **Daten:**  
  - `text`: Enth√§lt die transkribierten Texte aller Episoden.
  - `word_counts.csv`: Enth√§lt, wie oft welches Wort in welcher Episode vorkommt.
  - `episode_stats.json`: Statistiken zu jeder Episode (z.‚ÄØB. Wortanzahl, neue W√∂rter).
- **Visualisierung:** Mit Streamlit k√∂nnen W√∂rter gesucht und deren H√§ufigkeit √ºber die Episoden hinweg visualisiert werden.

## Nutzung

Getestet mit Python 3.11
ffmpeg muss installiert sein

   ```sh
   # F√ºr die Streamlit App
   pip install -r requirements.txt
   streamlit run app.py

   # F√ºr das Verarbeiten neuer Folgen 
   cd episode_processor
   pip install -r requirements.txt
   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
   python -m spacy download de_core_news_lg
   # F√ºr das Laden und Transkribieren
   python dpu_to_text.py
   # F√ºr das Z√§hlen der W√∂rter
   python word_counter.py
   ```



## Datenstruktur

- [`word_counts.csv`](word_counts.csv): Matrix mit Wortz√§hlungen pro Episode (ohne Stoppw√∂rter)
- [`episode_stats.json`](episode_stats.json): Enth√§lt f√ºr jede Episode:
  - `total_words`: Gesamtzahl der W√∂rter
  - `unique_words`: Anzahl unterschiedlicher W√∂rter
  - `new_words`: Neue W√∂rter in dieser Episode

## Beispiel-Workflow

1. RSS-Feed auslesen und MP3s herunterladen
2. Audiodateien mit Whisper transkribieren
3. Texte mit spaCy tokenisieren und analysieren
4. Ergebnisse in CSV/JSON speichern
5. Streamlit-App zur Auswertung nutzen

## Hinweise

- F√ºr GPU-Beschleunigung wird eine CUDA-f√§hige Grafikkarte empfohlen.
- Das Verarbiten einer Folge mit Whisper hat ca 20 minuten gedaurt, und l√§sst sich sicher noch optimieren
- Whisper hat teilweise Probleme mit der genauer Erkennung der W√∂rter, besonders wenn die beiden durcheinandere sprechen
- Auch spaCy hat probleme mit der lemmatisierung und es werden nicht alle W√∂rter zum korrekten Wortstamm zusammengefasst 

---
